{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malaria Parasite Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, classes) :\n",
    "    class_images = []\n",
    "    for cls in classes :\n",
    "        cls_imgs = []\n",
    "        img_names = os.listdir(path + cls + \"/\")\n",
    "        for img_name in img_names :\n",
    "                try :\n",
    "                    img = cv2.imread(path + cls + \"/\" + img_name)\n",
    "                    if not (img is None):\n",
    "                        cls_imgs.append(img)\n",
    "                except Exception as e :\n",
    "                    pass\n",
    "        class_images.append(np.array(cls_imgs))\n",
    "    return np.concatenate(class_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"/home/ajayrr/Parasite/Parasite/train/\"\n",
    "dataset = load_dataset(DATADIR, [\"Uninfected\", \"Parasitized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to apply gamma correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.0):\n",
    "    \t# build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "    for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blob Detection hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blob detection (Hyperparameters)\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "params.filterByArea = True\n",
    "params.maxArea = 200\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = True\n",
    "params.minConvexity = 0.3\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.0\n",
    "# Change thresholds\n",
    "params.minThreshold = -3;\n",
    "params.maxThreshold = 150;\n",
    "# Filter by Inertia\n",
    "params.filterByInertia = True\n",
    "params.minInertiaRatio = 0.0\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "# other hyperparameters\n",
    "IMG_SIZE = 90\n",
    "gamma = 0.95\n",
    "smoothening_kernel_size = 5\n",
    "smoothening_degree = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blob Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the path of the image files and returns a dataframe with the number of blobs as feature\n",
    "def get_blob_features(dataset):\n",
    "    dataframe = [[],[],[]]\n",
    "    for img in dataset:\n",
    "        if not (img is None):\n",
    "            img_ = cv2.resize(img,(IMG_SIZE, IMG_SIZE))\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(2,2))\n",
    "            img_ = cv2.dilate(img_,kernel,iterations = 1)\n",
    "            img_ = adjust_gamma(img_, gamma)\n",
    "            keypoints = detector.detect(img_)\n",
    "            dataframe[0].append(len(keypoints))\n",
    "            if(len(keypoints) >= 2):\n",
    "                dataframe[1].append(keypoints[0].size)\n",
    "                dataframe[2].append(keypoints[1].size)\n",
    "            elif(len(keypoints) == 1):\n",
    "                dataframe[1].append(keypoints[0].size)\n",
    "                dataframe[2].append(0)\n",
    "            else:\n",
    "                dataframe[1].append(0)\n",
    "                dataframe[2].append(0)\n",
    "    return np.asarray(dataframe).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contour Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the path of the image files and returns a dataframe with the 5 features\n",
    "def get_contour_features(dataset):\n",
    "    dataframe = [[],[],[],[],[]]\n",
    "    for img in dataset:\n",
    "        img_ = cv2.GaussianBlur(img, (3,3), 2)\n",
    "        if not (img_ is None):\n",
    "            img_gray = cv2.cvtColor(img_, cv2.COLOR_BGR2GRAY)\n",
    "            ret, thresh = cv2.threshold(img_gray,127,255,0)\n",
    "            _,contours,_ = cv2.findContours(thresh,1,2)\n",
    "\n",
    "            for i in range(5):\n",
    "                try:\n",
    "                    area = cv2.contourArea(contours[i])\n",
    "                    dataframe[i].append(area)\n",
    "                except:\n",
    "                    dataframe[i].append(0)\n",
    "\n",
    "    return (np.asarray(dataframe).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_contours(dataset):\n",
    "    dataframe = []\n",
    "    for img in dataset:\n",
    "        if not (img is None):\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            edged = cv2.Canny(gray, 30 , 200)\n",
    "            _,contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "            dataframe.append(len(contours))\n",
    "    return (np.asarray(dataframe).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Visual Words \n",
    "##### 1. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_LUCID_features(train_img):\n",
    "    lucid_keypoints = []\n",
    "    count = 0\n",
    "    rmv_index_train = []\n",
    "    for image in train_img :\n",
    "         if not (image is None):\n",
    "            image = cv2.resize(image, (50, 50))\n",
    "            # image =cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            detector = cv2.FastFeatureDetector_create()\n",
    "            kp = detector.detect(image,None)\n",
    "            lucid = cv2.xfeatures2d.LUCID_create()\n",
    "            kp, descriptors = lucid.compute(image,kp)\n",
    "            if descriptors is not None:\n",
    "                descriptors = np.array(descriptors)\n",
    "                lucid_keypoints.append(descriptors)\n",
    "\n",
    "                temp = descriptors\n",
    "            else:\n",
    "\n",
    "                lucid_keypoints.append(temp)\n",
    "\n",
    "           \n",
    "    lucid_keypoints = np.concatenate(lucid_keypoints, axis=0)\n",
    "    kmeans = KMeans(n_clusters = 16).fit(lucid_keypoints)\n",
    "    print(lucid_keypoints.shape)\n",
    "    print(\"--------Computed descriptors--------\")\n",
    "\n",
    "    x_Siftfeat_train = calculate_lucid_histogram(train_img, kmeans)\n",
    "    print(\"------Computed Histogram-----\")\n",
    "\n",
    "    return x_Siftfeat_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FAST (Features from Accelerated Segment Test) algorithm was used to detect the keypoints of the images.\n",
    "The LUCID (Locally Uniform Comparision Image Descriptor) is used to get the descriptors for the keypoints. The points are clustered using the K-means clustering algorithm. The value of K was determined using the elbow method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lucid_histogram(images, model):\n",
    "    feature_vectors=[]\n",
    "    rmv_index_test = []\n",
    "    for image in images :\n",
    "        if not (image is None):\n",
    "            # image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            #feature extraction\n",
    "            detector = cv2.FastFeatureDetector_create()\n",
    "            kp = detector.detect(image,None)\n",
    "            lucid = cv2.xfeatures2d.LUCID_create()\n",
    "            kp, descriptors = lucid.compute(image,kp)\n",
    "            #classification of all descriptors in the model\n",
    "            if descriptors is not None :\n",
    "                predict_kmeans = model.predict(descriptors)\n",
    "                #calculates the histogram\n",
    "                hist, bin_edges = np.histogram(predict_kmeans, bins = 16)\n",
    "                #histogram is the feature vector\n",
    "                feature_vectors.append(hist)\n",
    "                temp = hist\n",
    "            else :\n",
    "                feature_vectors.append(temp)\n",
    "\n",
    "    feature_vectors=np.asarray(feature_vectors)\n",
    "\n",
    "    return np.array(feature_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary is constructed by creating a histogram and using the histogram as a feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining contour features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = get_contour_features(dataset)\n",
    "df1 = pd.DataFrame(data = data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining blob features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = get_blob_features(dataset)\n",
    "df2 = pd.DataFrame(data = data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining Bag of Visual Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480177, 27)\n",
      "--------Computed descriptors--------\n",
      "------Computed Histogram-----\n"
     ]
    }
   ],
   "source": [
    "data3 = generate_LUCID_features(dataset)\n",
    "df3 = pd.DataFrame(data = data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining number of contours feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = get_number_of_contours(dataset)\n",
    "df4 = pd.DataFrame(data = data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label = np.concatenate([np.zeros(int(dataset.shape[0]/2.)), np.ones(int(dataset.shape[0]/2.))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating the training label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfT = pd.DataFrame(data = training_label)\n",
    "df = pd.concat([dfT, df2, df1, df3, df4], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"features_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"features_combined.csv\")\n",
    "data = data.iloc[:,1:]\n",
    "\n",
    "\"\"\" Building the train_set and the test_set \"\"\"\n",
    "\n",
    "# seperating the training and validation test\n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy =  0.9529785303900816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "model = RandomForestClassifier(n_estimators=115,max_depth=10)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "x = accuracy_score(y_pred, y_test)\n",
    "print(\"Random Forest accuracy = \",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn accuracy = 0.9384638645297853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# K-Nearest neighbour classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "print(\"knn accuracy = \" + str(knn_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy =  0.9467795585122467\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"SVM accuracy = \",accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
